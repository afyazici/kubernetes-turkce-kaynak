# Kubernetes


## Kubernetes Nedir?
- **Kubernetes**, aÃ§Ä±k kaynaklÄ± bir konteyner yÃ¶netim aracÄ±dÄ±r.
- Google tarafÄ±ndan geliÅŸtirilmiÅŸtir.
- FarklÄ± daÄŸÄ±tÄ±m ortamlarÄ±nda konteynerleÅŸtirilmiÅŸ uygulamalarÄ± yÃ¶netmenize yardÄ±mcÄ± olur.
    - fiziksel ortamda
    - sanal ortamda
    - bulut ortamÄ±nda

## Kubernetes'Ä±n AvantajlarÄ±:

- **YÃ¼ksek eriÅŸilebilirlik** veya kesintisiz Ã§alÄ±ÅŸma
- **Ã–lÃ§eklenebilirlik** veya yÃ¼ksek performans
- **Afet kurtarma** - yedekleme ve geri yÃ¼kleme

## Kubernetes Components
### Pod
* Pod Kubernete's en kÃ¼Ã§Ã¼k birimidir.
* Konteyner Ã¼zerinde sanallaÅŸtÄ±rma yapar. (abstraction)

![](images/1.png)


* YalnÄ±zca Kubernetes katmanÄ±yla etkileÅŸime geÃ§eriz.
* Bir pod iÃ§inde birden fazla konteyner Ã§alÄ±ÅŸtÄ±rabilirsiniz, ancak genellikle bir pod baÅŸÄ±na bir uygulama bulunur.
* Her pod kendi IP adresine sahiptir. Her pod, birbirleriyle bu internal IP adresini kullanarak iletiÅŸim kurabilir.
* Ancak, Kubernetes'teki pod bileÅŸenleri de geÃ§icidir: yani Ã§ok kolay bir ÅŸekilde Ã¶lebilirler. Ã–rneÄŸin, bir veritabanÄ± konteyneri kaybedersem, konteyner iÃ§indeki uygulama Ã§Ã¶ktÃ¼ÄŸÃ¼ veya sunucu kaynaklarÄ± tÃ¼kendiÄŸi iÃ§in pod Ã¶lÃ¼r ve yerine yeni bir tane oluÅŸturulur ve bu durumda yeni bir IP adresi atanÄ±r. Bu, veritabanÄ±yla IP adresini kullanarak iletiÅŸim kuruyorsak elbette sakÄ±ncalÄ±dÄ±r, her pod yeniden baÅŸladÄ±ÄŸÄ±nda her seferinde yeniden ayarlamamÄ±z gerekir. Bu nedenle, pod'un yeniden baÅŸladÄ±ÄŸÄ±nda IP adresini ayarlamanÄ±za gerek kalmadan veritabanÄ±yla iletiÅŸim kurmanÄ±zÄ± saÄŸlayan baÅŸka bir Kubernetes bileÅŸeni olan `Service` kullanÄ±lÄ±r.
### Service and Ingress,

* Service, her bir pod'a baÄŸlanabilen sabit bir IP adresidir. UygulamamÄ±zÄ±n kendi `service`'i olacak ve veritabanÄ± pod'u kendi `service`'ine sahip olacak. Buradaki gÃ¼zel ÅŸey, servis ve Pod'un yaÅŸam dÃ¶ngÃ¼leri birbirine baÄŸlÄ± deÄŸil, bu yÃ¼zden Pod Ã¶lse bile `Service` ve IP adresi kalÄ±r. ArtÄ±k endpoint'i deÄŸiÅŸtirmemize gerek yoktur.

![](images/2.png)

* Tabii ki, uygulamamÄ±zÄ±n bir tarayÄ±cÄ± aracÄ±lÄ±ÄŸÄ±yla eriÅŸilebilir olmasÄ±nÄ± isteriz deÄŸil mi? Bunun iÃ§in bir `external service` oluÅŸturmamÄ±z gerekir. `External Service`, dÄ±ÅŸ kaynaklardan iletiÅŸimi aÃ§an bir servistir. Ancak, veritabanÄ±mÄ±zÄ± halka aÃ§Ä±k isteklere aÃ§mak istemeyiz. Bunun iÃ§in `Internal Service` adÄ±nÄ± verdiÄŸimiz bir ÅŸey oluÅŸtururuz.

![](images/3.png)

* External Service URL'sinin Ã§ok pratik olmadÄ±ÄŸÄ±nÄ± fark ettiniz mi? Temelde, bir HTTP protokolÃ¼yle bir node IP adresi ve service port numarasÄ±na sahibiz. Bu hÄ±zlÄ± bir ÅŸekilde bir ÅŸeyleri test etmek istiyorsak iyidir, ancak end-product iÃ§in iyi deÄŸildir. Genellikle, uygulamamÄ±zla gÃ¼venli bir protokol ve bir alan adÄ± kullanmak isteriz.

![](images/4.png)

Bunun iÃ§in Kubernetes'in baÅŸka bir bileÅŸeni olan `Ingress` var. Bu ÅŸekilde, istek Ã¶nce service'e deÄŸil, Ingress'e gider ve oradan Service'e yÃ¶nlendirilir.

![](images/5.png)

* Åimdi, Kubernetes'in Ã§ok temel bileÅŸenlerini gÃ¶rdÃ¼k ve gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, bu Ã§ok basit bir kurulum, sadece bir sunucu ve birkaÃ§ konteyner Ã§alÄ±ÅŸtÄ±rÄ±yoruz ve bazÄ± component'ler var.
### ConfigMap and Secret

Yani, pod'lar birbirleriyle `service` aracÄ±lÄ±ÄŸÄ±yla iletiÅŸim kurar. UygulamamÄ±zÄ±n, veritabanÄ± ile iletiÅŸim kurmak iÃ§in kullandÄ±ÄŸÄ± bir database endpoint `Ã¶rneÄŸin mongodb service`'i olacak. Ancak bu veritabanÄ± URL'sini (ya da endpoint) genellikle nerede yapÄ±landÄ±rÄ±rÄ±z?

![](images/6.png)

Genellikle bunu application properties file veya bazÄ± external environmental variable olarak yaparÄ±z, ancak genellikle yapÄ±landÄ±rma,uygulamanÄ±n iÃ§erisindeki built image'tedir.

Ã–rneÄŸin, service endpoint (ya da service name) 'mongodb' olarak deÄŸiÅŸirse, uygulamadaki bu URL'yi ayarlamalÄ±yÄ±z. Genellikle yeni bir sÃ¼rÃ¼mle uygulamayÄ± rebuild etmemiz ve repoya pushlamamÄ±z gerekir. ArdÄ±ndan bu yeni image'i pod'umuzda pull'layÄ±p tÃ¼m uygulamayÄ± yeniden baÅŸlatmamÄ±z gerekebilir.

![](images/7.png)

Yani, veritabanÄ± URL'si gibi kÃ¼Ã§Ã¼k bir deÄŸiÅŸiklik iÃ§in bu gerÃ§ekten zahmetli. Bu sebeple, Kubernetes'in `configmap` adÄ±nda bir bileÅŸeni var. YapÄ±sÄ±, uygulamamÄ±za `external configuration` saÄŸlar. ConfigMap genellikle kullandÄ±ÄŸÄ±mÄ±z veritabanÄ± URL'leri gibi yapÄ±landÄ±rma verilerini iÃ§erir. Kubernetes'te bunu Pod'a baÄŸlarÄ±z. Pod, ConfigMap'in iÃ§erdiÄŸi verileri alÄ±r. Ve ÅŸimdi, service adÄ±nÄ± deÄŸiÅŸtirirsek (service end point), sadece ConfigMap'i ayarlarÄ±z ve bu yeterli olacaktÄ±r. Yeni bir image oluÅŸturmamÄ±za ve tÃ¼m dÃ¶ngÃ¼yÃ¼ geÃ§irmemize gerek yoktur. BÃ¼yÃ¼k avantaj!

![](images/8.png)

Åimdi, external configuration bir parÃ§asÄ± aynÄ± zamanda database kullanÄ±cÄ± adÄ± ve ÅŸifresi olabilir deÄŸil mi? Bu da uygulama daÄŸÄ±tÄ±m sÃ¼recinde deÄŸiÅŸebilir. Ancak, bir ÅŸifreyi veya diÄŸer kimlik bilgilerini dÃ¼z metin formatÄ±nda bir configmap'e koymamÄ±z gÃ¼vensiz olurdu.

![](images/9.png)

Bu amaÃ§la, Kubernetes'in `Secret` adÄ±nda baÅŸka bir bileÅŸeni vardÄ±r. Yani, Secret, ConfigMap gibi, ancak fark ÅŸu ki; ÅŸifre gibi gizli verileri saklamak iÃ§in kullanÄ±lÄ±r. Ve tabii ki, dÃ¼z metin formatÄ±nda deÄŸil, base64 formatÄ±nda kodlanmÄ±ÅŸ olarak saklanÄ±r. Yani, Secret, kullanÄ±cÄ± adlarÄ± gibi kimlik bilgilerini iÃ§erecek ve tabii ki, veritabanÄ± kullanÄ±cÄ±larÄ±nÄ± iÃ§erecektir. ConfigMap'e de koyabiliriz, ancak Ã¶nemli olan ÅŸifreler, sertifikalar, baÅŸkalarÄ±nÄ±n eriÅŸimini istemediÄŸimiz ÅŸeyler Secret'e girer. AynÄ± ConfigMap gibi, sadece Pod'umuza baÄŸlarÄ±z, bÃ¶ylece Pod bu verileri gÃ¶rebilir ve Secret'ten okuyabilir. ConfigMap veya Secret'ten verileri, Ã¶rneÄŸin environment variables olarak veya hatta bir Ã¶zellikler dosyasÄ± olarak uygulamamÄ±zÄ±n iÃ§inde kullanabiliriz.

![](images/10.png)

AslÄ±nda en Ã§ok kullanÄ±lan Kubernetes temel bileÅŸenlerinin neredeyse tamamÄ±nÄ± gÃ¶rdÃ¼k. Pod'a gÃ¶z attÄ±k. Hizmetlerin nasÄ±l kullanÄ±ldÄ±ÄŸÄ±nÄ±, Ingress bileÅŸeninin ne iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼k ve ayrÄ±ca ConfigMap ve Secrets'Ä± kullanan harici yapÄ±landÄ±rmayÄ± da gÃ¶rdÃ¼k.

![](images/11.png)

### Volumes
Åimdi genel olarak Ã§ok Ã¶nemli bir kavramÄ± inceleyelim, bu da ==veri depolama== ve Kubernetes iÃ§erisinde nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±dÄ±r. Yani, uygulamamÄ±zÄ±n kullandÄ±ÄŸÄ± bir database partÄ±mÄ±z var ve bir miktar verimiz var. Åu anda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z bu kurulumla, eÄŸer veritabanÄ± container veya pod'u yeniden baÅŸlatÄ±lÄ±rsa, veri kaybolur. Ve bu aÃ§Ä±kÃ§a sorunlu ve elveriÅŸsizdir, Ã§Ã¼nkÃ¼ database'deki verilerinizin veya gÃ¼nlÃ¼k verilerinizin uzun sÃ¼reli gÃ¼venilir bir ÅŸekilde kalÄ±cÄ± olmasÄ±nÄ± istersiniz. Ve bunu Kubernetes'te yapmanÄ±n yolu, Kubernetes'in baÅŸka bir bileÅŸeni olan `Volumes` kullanmaktÄ±r.

![](images/12.png)

Ve ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r: Temelde bir fiziksel depolama birimini, yani bir sabit diski, pod'unuza baÄŸlar. Ve bu depolama ya yerel bir makinede olabilir, yani pod'un Ã§alÄ±ÅŸtÄ±ÄŸÄ± aynÄ± sunucu node'unda olabilir, ya da Kubernetes kÃ¼mesinin dÄ±ÅŸÄ±nda anlamÄ±na gelen uzak bir depolama olabilir. Bulut depolama olabilir veya Kubernetes kÃ¼mesinin bir parÃ§asÄ± olmayan kendi yerleÅŸke depolamanÄ±z olabilir, bu yÃ¼zden bununla ilgili external reference var.

![](images/13.png)

BÃ¶ylece, database pod'u veya caontainer yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda, tÃ¼m veri kalÄ±cÄ± bir ÅŸekilde saklanmÄ±ÅŸ olacaktÄ±r.

Kubernetes kÃ¼mesi ve tÃ¼m bileÅŸenlerinin ve depolama arasÄ±ndaki farkÄ± anlamanÄ±z Ã¶nemlidir, yerel veya uzak bir depolama olmasÄ± fark etmeksizin, depolamayÄ± Kubernetes kÃ¼mesine takÄ±lmÄ±ÅŸ harici bir sabit diske benzetebilirsiniz. Ã‡Ã¼nkÃ¼ point is, Kubernetes kÃ¼mesi aÃ§Ä±kÃ§a hiÃ§bir veri kalÄ±cÄ±lÄ±ÄŸÄ±nÄ± yÃ¶netmez, bu da Kubernetes kullanÄ±cÄ±sÄ± veya yÃ¶neticisi olarak sizin veriyi yedeklemenizden, Ã§oÄŸaltmanÄ±zdan, yÃ¶netmenizden ve uygun donanÄ±mda saklamanÄ±zdan emin olmanÄ±z gerektiÄŸi anlamÄ±na gelir, Ã§Ã¼nkÃ¼ Kubernetes bununla ilgilenmez.

### Deployment and Stateful Set

Åimdi, her ÅŸey mÃ¼kemmel bir ÅŸekilde Ã§alÄ±ÅŸÄ±yor ve bir kullanÄ±cÄ± bir tarayÄ±cÄ± aracÄ±lÄ±ÄŸÄ±yla uygulamaya eriÅŸebiliyor. Åimdi, bu kurulumla, application pod'u Ã¶lÃ¼rse, crashlerse veya yeni bir container image oluÅŸturduÄŸum iÃ§in pod'u restart etmem gerekiyorsa ne olurdu? Basically, bir kullanÄ±cÄ±nÄ±n uygulamama ulaÅŸamadÄ±ÄŸÄ± bir sÃ¼re olan bir kesintim olurdu, bu da end product'ta gerÃ§ekleÅŸirse Ã§ok kÃ¶tÃ¼ bir durumdur.

![](images/14.png)

Ve bu, distributed systems ve containers avantajÄ± tam olarak budur. Yani, yalnÄ±zca 1 application pod'u ve 1 database pod'u gibi bir ÅŸeye gÃ¼venmek yerine, her ÅŸeyi birden fazla sunucuda replikasÄ±nÄ± oluÅŸturuyoruz. Yani, uygulamamÄ±zÄ±n bir klonu veya Ã§oÄŸaltmasÄ± Ã§alÄ±ÅŸacaÄŸÄ± baÅŸka bir node olacak ve bu da service'e baÄŸlÄ± olacak. HatÄ±rlarsanÄ±z Ã¶nceki olarak service'in, bir pod Ã¶ldÃ¼ÄŸÃ¼nde end point'i sÃ¼rekli ayarlamamÄ±za gerek olmadÄ±ÄŸÄ± iÃ§in bir kalÄ±cÄ± statik IP adresi ve bir DNS adÄ± gibi olduÄŸunu sÃ¶ylemiÅŸtik.

* Btw service aynÄ± zamanda bir `load balancer`dÄ±r. Yani, service isteÄŸi yakalayacak ve en az meÅŸgul olan pod'a yÃ¶nlendirecektir. Yani bu iki iÅŸlevi de vardÄ±r.


Ancak application pod'unun ikinci replikasÄ±nÄ± oluÅŸturmak iÃ§in ikinci bir pod oluÅŸturmazsÄ±nÄ±z, bunun yerine uygulama pod'unun bir blueprint'ini tanÄ±mlar ve o pod'un kaÃ§ tane replikasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rmak istediÄŸinizi belirtirsiniz. Ve bu component veya blueprint'e `deployment` denir, bu da Kubernetes'in baÅŸka bir componentidir. Pratikte, pod'larla Ã§alÄ±ÅŸmazsÄ±nÄ±z veya pod'lar oluÅŸturmazsÄ±nÄ±z; Ã§Ã¼nkÃ¼ orada kaÃ§ tane replika belirtebilir ve ihtiyacÄ±nÄ±z olan pod'larÄ±n replika sayÄ±sÄ±nÄ± artÄ±rabilir veya azaltabilirsiniz. Yani pod, container'larÄ±n Ã¼zerinde bir layer of abstraction ve deployment, podlarÄ±n Ã¼zerinde baÅŸka bir layer of abstraction, bu da pod'larla etkileÅŸimi, kopyalama ve diÄŸer yapÄ±landÄ±rmalarÄ± daha kullanÄ±ÅŸlÄ± hale getirir.

![](images/15.png)

Yani pratikte, Ã§oÄŸunlukla pod'larla deÄŸil, deployment'larla Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z. Yani ÅŸimdi, uygulama pod'unuzun replikalarÄ±ndan biri Ã¶lÃ¼rse, service istekleri baÅŸkasÄ±na yÃ¶nlendirilecektir, bu yÃ¼zden uygulamanÄ±z kullanÄ±cÄ±lar iÃ§in hala eriÅŸilebilir olacaktÄ±r.

![](images/16.png)

Åimdi muhtemelen ÅŸunu merak ediyorsunuzdur, peki database pod'u ne olacak? Ã‡Ã¼nkÃ¼ eÄŸer database pod'u Ã¶lÃ¼rse, uygulamanÄ±z da eriÅŸilemez olacaktÄ±r. Bu yÃ¼zden, bir database replikasÄ±na da ihtiyacÄ±mÄ±z var. Ancak, _==bir `deployment` kullanarak bir databese'i kopyalayamayÄ±z==_. Bunun nedeni, database'in bir state'i olmasÄ±dÄ±r, yani veridir. Bu da demektir ki eÄŸer database'in replikalarÄ± veya klonlarÄ± olsaydÄ±, hepsi aynÄ± paylaÅŸÄ±lan data storage volume'Ã¼ne eriÅŸmek zorunda kalacaklardÄ±. Ve burada, hangi pod'larÄ±n ÅŸu anda depolama birimine yazdÄ±ÄŸÄ±nÄ± veya hangi pod'larÄ±n depolama biriminden okuduÄŸunu yÃ¶neten bir mekanizmaya ihtiyacÄ±nÄ±z olacaktÄ±. Bu mekanizma, Ã§oÄŸaltma Ã¶zelliklerinin yanÄ± sÄ±ra sunan baÅŸka bir Kubernetes bileÅŸeni olan `StatefulSet` ile saÄŸlanÄ±r.

![](images/17.png)

Bu bileÅŸen Ã¶zellikle database gibi uygulamalar iÃ§in tasarlanmÄ±ÅŸtÄ±r. Yani, MySQL, MongoDB, Elasticsearch veya herhangi bir diÄŸer stateful applications veya databases, deployments yerine Stateful Sets kullanÄ±larak oluÅŸturulmalÄ±dÄ±r. Bu Ã§ok Ã¶nemli bir ayrÄ±mdÄ±r. Ve StatefulSet, aynÄ± deployment gibi, pod'larÄ± replikalamayÄ± ve bunlarÄ± scaling'e alÄ±r ancak database reading ve writing iÅŸlemlerinin senkronize olduÄŸundan emin olur, bÃ¶ylece database tutarsÄ±zlÄ±klarÄ± olmaz.

![](images/18.png)

Ancak, bir Kubernetes kÃ¼mesinde StatefulSets kullanarak database uygulamalarÄ±nÄ± deploy etmek biraz zahmetli olabilir. Bu yÃ¼zden, database uygulamalarÄ±nÄ± Kubernetes kÃ¼mesinin dÄ±ÅŸÄ±nda barÄ±ndÄ±rmak ve yalnÄ±zca daÄŸÄ±tÄ±mlarÄ± veya durumsuz uygulamalarÄ± Kubernetes kÃ¼mesinin iÃ§inde sorunsuz bir ÅŸekilde Ã§oÄŸaltmak ve Ã¶lÃ§eklendirmek ve dÄ±ÅŸ database ile iletiÅŸim kurmak yaygÄ±n bir uygulamadÄ±r.

Åimdi, uygulama pod'umun iki replikasÄ± ve database'in iki kopyasÄ± olduÄŸunda ve hepsi load-balanced olduÄŸunda, kurulumumuz daha gÃ¼venlidir. Bu, eÄŸer Node 1(whole node1), yeniden baÅŸlatÄ±lsaydÄ± veya Ã§Ã¶kseydi ve Ã¼zerinde hiÃ§bir ÅŸey Ã§alÄ±ÅŸamaz hale gelse bile, hala uygulama ve database pod'larÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ± ikinci bir node'umuz olurdu. Uygulama, bu iki replikadan yeniden oluÅŸturulana kadar kullanÄ±cÄ± tarafÄ±ndan eriÅŸilebilir olacaktÄ±r, bu yÃ¼zden kesintiyi Ã¶nleyebilirsiniz.

![](images/19.png)

Ã–zetlemek gerekirse, en Ã§ok kullanÄ±lan Kubernetes bileÅŸenlerini inceledik. ParÃ§alar arasÄ±nda iletiÅŸim kurmak iÃ§in `pod`lar ve `service`lerle baÅŸladÄ±k, ve trafiÄŸi clusterlara yÃ¶nlendirmek iÃ§in kullanÄ±lan `Ingress` bileÅŸenini inceledik. AyrÄ±ca, `ConfigMaps` ve `Secret` kullanarak external configuration, ve `Volumes` kullanarak veri kalÄ±cÄ±lÄ±ÄŸÄ±nÄ± inceledik. Ve son olarak, `Deployments` ve `StatefulSets` gibi replicating ve blueprintlere baktÄ±k, burada stateful applications Ã¶zellikle databases gibi stateful applications iÃ§in kullanÄ±lÄ±r. Ve evet, Kubernetes'in sunduÄŸu Ã§ok daha fazla bileÅŸen var, ama bunlar gerÃ§ekten Ã§ekirdek, temel olanlar. Bu temel bileÅŸenleri kullanarak oldukÃ§a gÃ¼Ã§lÃ¼ Kubernetes kÃ¼mesi oluÅŸturabilirsiniz.

## Kubernetes Mimarisi
Kubernetes'in temel mimarisinden bahsedeceÄŸiz. Bu yÃ¼zden Kubernetes'in Ã§alÄ±ÅŸtÄ±ÄŸÄ± iki tÃ¼r node'u inceleyeceÄŸiz: biri `master` diÄŸeri ise `slave`. BunlarÄ±n arasÄ±ndaki fark nedir ve her birinin cluster iÃ§indeki rolÃ¼ nedir, onlara bakacaÄŸÄ±z.

Kubernetes'in ne yaptÄ±ÄŸÄ±nÄ± ve cluster'Ä±n nasÄ±l self-managed olduÄŸunu, self-healing ve automated olduÄŸunu gÃ¶steren temel kavramlarÄ± ele alacaÄŸÄ±z. Ve sizin gibi bir Kubernetes cluster operatÃ¶rÃ¼ olarak, Ã§ok daha az manuel Ã§aba harcamanÄ±z gerektiÄŸini gÃ¶receÄŸiz.
### Node Process

Ä°ki application parts Ã§alÄ±ÅŸtÄ±ÄŸÄ± tek bir node ile bu temel kurulumla baÅŸlayacaÄŸÄ±z. Kubernetes mimarisinin ana bileÅŸenlerinden biri worker servers veya node'dur. Her node, o node'da Ã§alÄ±ÅŸan birden fazla application pod'una sahip olacaktÄ±r.

Ve Kubernetes'in bunu yapma ÅŸekli, her node'da bulunmasÄ± gereken ve bu pod'larÄ± planlamak ve yÃ¶netmek iÃ§in kullanÄ±lan ==three process== kullanmasÄ±dÄ±r. Yani, node'lar, asÄ±l iÅŸi yapan cluster serverlardÄ±r.. Bu yÃ¼zden bazen onlara worker nodes da denir.

#### 1) container runtime

Her node'da Ã§alÄ±ÅŸmasÄ± gereken ilk sÃ¼reÃ§, `container runtime`dÄ±r. Benim Ã¶rneÄŸimde Docker var, ancak baÅŸka bir teknoloji de olabilir. Yani, applitacion pod'larÄ±nda iÃ§inde Ã§alÄ±ÅŸan containers olduÄŸu iÃ§in, her node'da bir `container runtime`  kurulmalÄ±dÄ±r.

#### 2) kubelet
Ancak pod'larÄ± ve bu pod'larÄ±n altÄ±ndaki container'larÄ± schedule eden aslÄ±nda `kubelet`tir, bu da Kubernetes'in bir parÃ§asÄ±dÄ±r. container runtime; hem konteyner Ã§alÄ±ÅŸma zamanÄ± hem de makine, yani node'un kendisiyle arayÃ¼zÃ¼ olduÄŸu gibi, sonuÃ§ta, kubelet bu config'i almak ve aslÄ±nda bir pod'u Ã§alÄ±ÅŸtÄ±rmak veya iÃ§inde bir container baÅŸlatmak ve ardÄ±ndan o node'dan container'e CPU, RAM ve depolama kaynaklarÄ± gibi kaynaklar atamakla sorumludur.

Bu nedenle, genellikle bir Kubernetes cluster, kurulu olmalÄ± ve `kubelet` hizmetlerine sahip birden fazla node'dan oluÅŸur. Ve bu worker nodes, bu Ã¶rnekteki application ve database pod'larÄ±nÄ±n replikalarÄ±nÄ± Ã§alÄ±ÅŸtÄ±racak yÃ¼zlerce diÄŸer node'u Ã§alÄ±ÅŸtÄ±rÄ±r.

Ve aralarÄ±ndaki iletiÅŸim ÅŸekli, `services` kullanÄ±lmasÄ±dÄ±r, bu da isteÄŸi application parÃ§asÄ±na veya Ã¶rneÄŸin bir database'e yÃ¶nlendiren bir `load-balancer` gibi Ã§alÄ±ÅŸÄ±r ve ardÄ±ndan ilgili parÃ§aya yÃ¶nlendirir.

#### 3) kube-proxy

Hizmetlerden pod'lara istekleri iletmekten sorumlu Ã¼Ã§Ã¼ncÃ¼ sÃ¼reÃ§ aslÄ±nda `kube-proxy`dir ve her node'da kurulmalÄ±dÄ±r. Kube-proxy, dÃ¼ÅŸÃ¼k bir iÅŸlem yÃ¼kÃ¼ ile performanslÄ± bir ÅŸekilde iletiÅŸim kurulmasÄ±nÄ± saÄŸlayan akÄ±llÄ± yÃ¶nlendirme mantÄ±ÄŸÄ±na sahiptir.

Ã–rneÄŸin, bir uygulama, uygulama replikasÄ±, bir database'e bir istek yapÄ±yorsa, hizmet sadece isteÄŸi rastgele bir replikaya yÃ¶nlendirmek yerine, isteÄŸi baÅŸlatan pod'un Ã§alÄ±ÅŸtÄ±ÄŸÄ± aynÄ± dÃ¼ÄŸÃ¼mde Ã§alÄ±ÅŸan replikaya yÃ¶nlendirecektir. Bu ÅŸekilde, isteÄŸi baÅŸka bir makineye gÃ¶ndermekle ilgili `aÄŸ iÅŸlem yÃ¼kÃ¼nden` kaÃ§Ä±nÄ±lmÄ±ÅŸ olur.

==To summarize, two Kubernetes processes, `kubelet` and `kube-proxy`, must be installed on every Kubernetes worker node==, along with an independent container runtime, in order for the Kubernetes cluster to function properly.

Ã–zetlemek gerekirse; bir kubernetes cluster'Ä±nÄ±n dÃ¼zgÃ¼n Ã§alÄ±ÅŸabilmesi iÃ§in `kubelet` ve `kube-proxy` her worker node  iÃ§erisine `container runtime` ile birlikte kurulmalÄ±dÄ±r.

![](images/20.png)

Ancak ÅŸimdi soru ÅŸu: Bu cluster ile nasÄ±l interact? Yeni bir application pod'u veya database pod'u nerede schedule edilmeli? Bir replika pod'u Ã¶lÃ¼rse, hangi process monitors ve reschedules veya restarts?
### Master Node

Yani, Master servers veya master nodes iÃ§erisinde tamamen farklÄ± processler Ã§alÄ±ÅŸtÄ±rÄ±r. Ve bunlar, cluster state ve worker nodes'larÄ± kontrol eden ==her yÃ¶netici dÃ¼ÄŸÃ¼mÃ¼nde Ã§alÄ±ÅŸan dÃ¶rt sÃ¼reÃ§tir==.

#### 1) API Server

Ä°lk hizmet API server. BÄ°r Kubernetes cluster'Ä±nda yeni bir application deploy etmek istediÄŸinizde, bir kullanÄ±cÄ± olarak API server ile interact edersiniz. Bir Kubernetes Dashboard gibi bir kullanÄ±cÄ± arayÃ¼zÃ¼ olabilir, `kubectl` gibi bir command-line tool veya bir Kubernetes API'si olabilir. Yani, API sunucusu, cluster iÃ§ine herhangi bir gÃ¼ncelleme talebinin veya hatta kÃ¼meden gelen sorgularÄ±n ilk isteÄŸini alÄ±r. Ve yalnÄ±zca kimlik doÄŸrulamasÄ±(auth) yaparak, yalnÄ±zca kimlik doÄŸrulanmÄ±ÅŸ ve yetkilendirilmiÅŸ isteklerin kÃ¼melere iletilmesini saÄŸlar.

![](images/21.png)

Bu, yeni pod'lar planlamak, yeni applications deploy etmek, yeni create new services veya herhangi bir components oluÅŸturmak istediÄŸinizde, isteÄŸinizi master node API sunucusuna iletmek zorunda olduÄŸunuz anlamÄ±na gelir. API server daha sonra requestinizi doÄŸrular. Ve her ÅŸey yolundaysa, isteÄŸinizi diÄŸer sÃ¼reÃ§lere ileterek istediÄŸiniz pod'u veya bileÅŸeni schedule iÃ§in bir node'a yÃ¶nlendirir.

![](images/22.png)

AyrÄ±ca, daÄŸÄ±tÄ±mÄ±nÄ±zÄ±n durumu veya cluster health etc., gibi sorgu isteklerini yapmak isterseniz, API sunucusuna bir istek gÃ¶nderir ve o da size yanÄ±t verir, bu da gÃ¼venlik aÃ§Ä±sÄ±ndan iyidir Ã§Ã¼nkÃ¼ clusterlara yalnÄ±zca `one entry point` vardÄ±r.

#### 2) Scheduler

BaÅŸka bir Master process ise Scheduler'dÄ±r. Yani, API serverÄ±na yeni bir pod schedule isteÄŸi gÃ¶nderdiÄŸinizde, API server, isteÄŸinizi doÄŸruladÄ±ktan sonra, gerÃ§ekte bu pod'un bir worker nodes'da baÅŸlatÄ±lmasÄ± iÃ§in `Scheduler`'a teslim eder.

Ve tabii ki, herhangi bir node'u rastgele atamak yerine, Scheduler, bir sonraki pod'un hangi belirli worker node'un scheduled olacaÄŸÄ± konusunda zekice bir ÅŸekilde karar vermesi gerekmektedir. Ä°lk olarak, isteÄŸinizi kontrol eder ve planlamak istediÄŸiniz uygulamanÄ±n ne kadar kaynaÄŸa ihtiyacÄ± olduÄŸunu kontrol eder. howmuch CPU, ne kadar RAM gibi..

Ve sonra, worker nodes'daki kullanÄ±labilir kaynaklarÄ± kontrol eder. EÄŸer bir node'un en Ã§ok kaynaÄŸa sahip olduÄŸunu sÃ¶ylÃ¼yorsa, yeni pod'u o node'a planlar.

![](images/23.png)

Ã–nemli bir nokta ÅŸu ki, scheduler sadece yeni bir pod'un hangi dÃ¼ÄŸÃ¼me planlanacaÄŸÄ±na karar verir. AsÄ±l planlamayÄ± yapan ve pod'u konteyner ile baÅŸlatan iÅŸlem ise `kubelet`'tir. Yani kubelet, scheduler'dan gelen isteÄŸi alÄ±r ve bu isteÄŸi ilgili node Ã¼zerinde yÃ¼rÃ¼tÃ¼r.
#### 3) Controller Manager

Bir sonraki Ã¶nemli bileÅŸen ise `controller manager`'dÄ±r. Bu bileÅŸen, herhangi bir dÃ¼ÄŸÃ¼mde pod'lar Ã¶ldÃ¼ÄŸÃ¼nde ne olacaÄŸÄ± sorusu aÃ§Ä±sÄ±ndan kritik Ã¶neme sahiptir. Ã–lÃ¼ node'larÄ± tespit etmek ve daha sonra bu pod'larÄ± en kÄ±sa sÃ¼rede reschedule etmek gerekir.

![](images/24.png)

DolayÄ±sÄ±yla controller manager, state changes'larÄ±, Ã¶rneÄŸin pod'larÄ±n Ã§Ã¶kmesini tespit eder. Pod'lar Ã¶ldÃ¼ÄŸÃ¼nde controller manager bunu algÄ±lar ve cluster state'ini mÃ¼mkÃ¼n olan en kÄ±sa sÃ¼rede kurtarmaya Ã§alÄ±ÅŸÄ±r.

Bu amaÃ§la, Ã¶len pod'larÄ± yeniden schedule iÃ§in scheduler'a bir istek gÃ¶nderir. Bu dÃ¶ngÃ¼ iÃ§inde, scheduler kaynak hesaplamasÄ±na gÃ¶re hangi worker node'larÄ±n bu pod'larÄ± tekrar baÅŸlatmasÄ± gerektiÄŸine karar verir ve bu worker node'Lar Ã¼zerindeki ilgili `kubelet`lere aslÄ±nda pod'larÄ± yeniden baÅŸlatmalarÄ± iÃ§in istek gÃ¶nderir.

![](images/25.png)

#### 4) Etcd
Son olarak, ana iÅŸlemlerden biri olan etcd, bir cluster state'inin key-value deposudur. Bunu aslÄ±nda bir cluster beyni olarak dÃ¼ÅŸÃ¼nebilirsiniz. Yani cluster'daki her deÄŸiÅŸiklik, Ã¶rneÄŸin yeni bir pod schedule edildiÄŸinde veya bir pod Ã¶ldÃ¼ÄŸÃ¼nde, tÃ¼m bu deÄŸiÅŸiklikler etcd'nin bu key-value deposunda kaydedilir veya gÃ¼ncellenir.

![](images/26.png)

Etcd deposunun bir kÃ¼me beyni olarak adlandÄ±rÄ±lmasÄ±nÄ±n sebebi, scheduler, controller manager gibi tÃ¼m bu mekanizmalarÄ±n, etcd'nin sahip olduÄŸu veriler sayesinde Ã§alÄ±ÅŸmasÄ±dÄ±r.

![](images/27.png)

Ã–rneÄŸin, scheduler her bir worker node'unda hangi kaynaklarÄ±n mevcut olduÄŸunu nasÄ±l bilir? Veya controller manager, cluster durumunda bir deÄŸiÅŸiklik olduÄŸunu nasÄ±l tespit eder?

Ã–rnek olarak, pod'larÄ±n Ã¶lmesi, kubelet'in scheduler'Ä±n isteÄŸi Ã¼zerine yeni pod'larÄ± baÅŸlatmasÄ±, API sunucusuna cluster health hakkÄ±nda bir sorgu gÃ¶ndermeniz veya uygulama daÄŸÄ±tÄ±m durumunuz gibi durumlar. API sunucusu tÃ¼m bu durum bilgilerini nereden alÄ±r?

TÃ¼m bu bilgiler etcd kÃ¼mesinde saklanÄ±r. Etcd'nin key-value deposunda saklanmayan ÅŸey ise gerÃ§ek uygulama verileridir. Ã–rneÄŸin, bir cluster iÃ§inde Ã§alÄ±ÅŸan bir database uygulamanÄ±z varsa, veriler etcd'de deÄŸil, baÅŸka bir yerde saklanÄ±r. Bu, yalnÄ±zca master iÅŸlemlerinin worker iÅŸlemleriyle ve tersiyle iletiÅŸim kurmasÄ± iÃ§in kullanÄ±lan bir cluster state bilgisidir.

ArtÄ±k muhtemelen ana iÅŸlemlerin, Ã¶zellikle de verileri gÃ¼venilir bir ÅŸekilde saklanmasÄ± veya Ã§oÄŸaltÄ±lmasÄ± gereken etcd deposunun, cluster operasyonu iÃ§in kritik Ã¶neme sahip olduÄŸunu anlamÄ±ÅŸsÄ±nÄ±zdÄ±r. Bu nedenle, uygulamada bir Kubernetes kÃ¼mesi genellikle birden fazla master'dan oluÅŸur. Her bir master dÃ¼ÄŸÃ¼mÃ¼ kendi ana iÅŸlemlerini Ã§alÄ±ÅŸtÄ±rÄ±r; elbette API sunucusu load-balanced'dÄ±r ve etcd deposu tÃ¼m master dÃ¼ÄŸÃ¼mleri arasÄ±nda distributed bir depolama oluÅŸturur.

![](images/28.png)



## Ã–rnek Cluster YapÄ±sÄ±


Åimdi worker ve master node'larÄ±nda Ã§alÄ±ÅŸan iÅŸlemleri gÃ¶rdÃ¼kten sonra, gerÃ§ek hayattaki bir cluster kurulumuna bakalÄ±m. Ã‡ok kÃ¼Ã§Ã¼k bir cluster'da muhtemelen iki master node ve Ã¼Ã§ worker node olur.

![](images/29.png)

Burada dikkat edilmesi gereken bir diÄŸer nokta ise master node sunucularÄ±nÄ±n donanÄ±m kaynaklarÄ±nÄ±n aslÄ±nda farklÄ± olmasÄ±dÄ±r. Master iÅŸlemleri daha Ã¶nemlidir, ancak aslÄ±nda daha az iÅŸ yÃ¼kÃ¼ne sahiptirler. DolayÄ±sÄ±yla CPU, RAM ve depolama gibi daha az kaynaÄŸa ihtiyaÃ§ duyarlar. Worker node'larÄ± ise, containerlarÄ± Ã§alÄ±ÅŸtÄ±ran pod'larÄ± barÄ±ndÄ±rma gibi asÄ±l iÅŸi yaparlar.

Bu nedenle, worker node'larÄ±nÄ±n daha fazla kaynaÄŸa ihtiyacÄ± vardÄ±r. UygulamanÄ±zÄ±n karmaÅŸÄ±klÄ±ÄŸÄ± ve kaynak gereksinimi arttÄ±kÃ§a, aslÄ±nda cluster'Ä±nÄ±za daha fazla master ve worker node'u ekleyerek daha gÃ¼Ã§lÃ¼ ve saÄŸlam bir kÃ¼me oluÅŸturabilirsiniz. BÃ¶ylece uygulama kaynak gereksinimlerinizi karÅŸÄ±layabilirsiniz.

![](images/30.png)

Var olan bir Kubernetes cluster'Ä±nda yeni master veya worker serverlarÄ± eklemek aslÄ±nda oldukÃ§a kolaydÄ±r. Bir master sunucusu eklemek istiyorsanÄ±z, yeni bir bare metal sunucu edinin, Ã¼zerine tÃ¼m master iÅŸlemlerini kurun ve onu Kubernetes kÃ¼mesine ekleyin.

AynÄ± ÅŸekilde, iki worker node'unda ihtiyacÄ±nÄ±z varsa, bare metal sunucular edinin, container runtime, kubelet ve kube-proxy gibi tÃ¼m worker dÃ¼ÄŸÃ¼mÃ¼ iÅŸlemlerini Ã¼zerlerine kurun ve onlarÄ± Kubernetes kÃ¼mesine ekleyin. Ä°ÅŸte bu kadar.

Bu ÅŸekilde, uygulama karmaÅŸÄ±klÄ±ÄŸÄ± ve kaynak gereksinimi arttÄ±kÃ§a, Kubernetes kÃ¼menizinin gÃ¼cÃ¼nÃ¼ ve kaynaklarÄ±nÄ± sonsuza kadar artÄ±rabilirsiniz.


## Minikube ve Kubectl Lokal Kurulumu

### **Minikube Nedir?**

#### 1) Minikube

![](images/31.png)

Genellikle Kubernetes dÃ¼nyasÄ±nda bir production cluster kurduÄŸunuzda, aÅŸaÄŸÄ±daki gibi gÃ¶rÃ¼necektir.

![](images/32.png)

En az iki olmak Ã¼zere birden fazla Master'a sahip olacaksÄ±nÄ±z ve birden fazla worker node olacak. Worker dÃ¼ÄŸÃ¼mlerinin kendi ayrÄ± sorumluluklarÄ± vardÄ±r. Diyagramda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, her biri bir dÃ¼ÄŸÃ¼mÃ¼ temsil eden gerÃ§ek ayrÄ± sanal veya fiziksel makineleriniz olur.

Åimdi, yerel ortamÄ±nÄ±zda bir ÅŸey test etmek istiyorsanÄ±z veya yeni bir uygulama veya yeni bileÅŸenler daÄŸÄ±tarak Ã§ok hÄ±zlÄ± bir ÅŸekilde bir ÅŸey denemek istiyorsanÄ±z ve bunlarÄ± yerel makinenizde test etmek istiyorsanÄ±z, aÃ§Ä±kÃ§asÄ± bÃ¶yle bir cluster kurmak oldukÃ§a zor olacaktÄ±r. veya bellek ve CPU gibi yeterli kaynak yoksa imkansÄ±z bile olabilir. Ä°ÅŸte tam olarak bu kullanÄ±m durumu iÃ§in `Minikube` adÄ± verilen bu aÃ§Ä±k kaynaklÄ± araÃ§ var.

Minikube'un ne olduÄŸuna gelince, temelde hem master processleri hem de worker processleri tek bir node'da Ã§alÄ±ÅŸtÄ±ran tek node bir clusterdÄ±r. Bu node'da Ã¶nceden yÃ¼klenmiÅŸ bir Docker container runtime olacak ÅŸekilde konteynerleri veya konteynerli pod'larÄ± Ã§alÄ±ÅŸtÄ±rabileceksiniz.

![](images/33.png)

DizÃ¼stÃ¼ bilgisayarÄ±nÄ±zda VirtualBox veya baÅŸka bir hipervizÃ¶r aracÄ±lÄ±ÄŸÄ±yla Ã§alÄ±ÅŸacak. Yani temel olarak, Minikube dizÃ¼stÃ¼ bilgisayarÄ±nÄ±zda bir VirtualBox oluÅŸturacak ve burada gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z dÃ¼ÄŸÃ¼mler bu VirtualBox'ta Ã§alÄ±ÅŸacak.

Ã–zetlemek gerekirse, Minikube, yerel kurulumunuzda Kubernetes'i test etmek iÃ§in kullanabileceÄŸiniz dizÃ¼stÃ¼ bilgisayarÄ±nÄ±zda bir VirtualBox'ta Ã§alÄ±ÅŸan tek node bir Kubernetes clusterdÄ±r.

![](images/34.png)

DizÃ¼stÃ¼ bilgisayarÄ±nÄ±zda veya PC'nizde yerel makinenizde bir kÃ¼me veya mini kÃ¼me kurduktan sonra, kÃ¼meyle etkileÅŸim kurmak iÃ§in bir yola ihtiyacÄ±nÄ±z vardÄ±r. BileÅŸenler oluÅŸturmak, yapÄ±landÄ±rmak vb. isteyeceksiniz ve iÅŸte `kubectl` devreye giriyor.

#### 2) Kubectl

local makinenizde Minikube'u temsil eden bu virtual node'a sahip olduktan sonra, bu cluster ile etkileÅŸim kurmak iÃ§in bir yola ihtiyacÄ±nÄ±z vardÄ±r. DolayÄ±sÄ±yla dÃ¼ÄŸÃ¼mde pod'lar ve diÄŸer Kubernetes bileÅŸenleri oluÅŸturmanÄ±n bir yoluna ihtiyacÄ±nÄ±z vardÄ±r ve bunu Kubernetes clusterlarÄ± iÃ§in bir command line toolu olan `kubectl` kullanarak yapabilirsiniz.

Peki nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶relim. Minikube'un hem master hem de worker processleri Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ± sÃ¶ylemiÅŸtik, bu nedenle API server adÄ± verilen master processlerden biri aslÄ±nda Kubernetes clusterÄ±n entry point noktasÄ±dÄ±r.

![](images/35.png)

Kubernetes'te bir ÅŸey yapmak istiyorsanÄ±z, herhangi bir ÅŸeyi yapÄ±landÄ±rmak istiyorsanÄ±z, Ã¶nce API sunucusuyla konuÅŸmanÄ±z gerekir. API sunucusuyla konuÅŸmanÄ±n yolu ise farklÄ± istemciler aracÄ±lÄ±ÄŸÄ±yla olur. Bir pano gibi bir UI arayÃ¼zÃ¼nÃ¼z olabilir, Kubernetes API'sini kullanarak konuÅŸabilir veya `kubectl` komut satÄ±rÄ± aracÄ±nÄ± kullanabilirsiniz.

![](images/36.png)

`kubectl` aslÄ±nda Ã¼Ã§ istemcinin de en gÃ¼Ã§lÃ¼sÃ¼dÃ¼r Ã§Ã¼nkÃ¼ `kubectl` ile Kubernetes'te istediÄŸiniz her ÅŸeyi yapabilirsiniz.

Bu video eÄŸitimleri boyunca Ã§oÄŸunlukla `kubectl` kullanacaÄŸÄ±z. `kubectl` API sunucusuna component oluÅŸturmak, component silmek vb. iÃ§in komutlar gÃ¶nderdikten sonra, Minikube node'undaki worker processler bunlarÄ± gerÃ§ekleÅŸtirecektir. AslÄ±nda pod'larÄ± oluÅŸturmak, pod'larÄ± yok etmek, services oluÅŸturmak vb. iÃ§in komutlarÄ± yÃ¼rÃ¼teceklerdir.

Bu, Minikube Ã§alÄ±ÅŸma ÅŸeklidir. `kubectl` cluster ile nasÄ±l kullanÄ±lÄ±r? Burada Ã¶nemli bir nokta, `kubectl`'nin yalnÄ±zca Minikube cluster iÃ§in olmadÄ±ÄŸÄ±dÄ±r. Bir cloud cluster'Ä±nÄ±z veya hibrit bir cluster'Ä±nÄ±z varsa, ne olursa olsun, `kubectl` herhangi bir Kubernetes kÃ¼mesi kurulumuyla etkileÅŸim kurmak iÃ§in kullanÄ±lan araÃ§tÄ±r. Bu nedenle burada unutulmamasÄ± Ã¶nemlidir.

![](images/37.png)

ArtÄ±k Minikube ve `kubectl`'nin ne olduÄŸunu bildiÄŸimize gÃ¶re, onlarÄ± pratikte gÃ¶rmek iÃ§in gerÃ§ekten kuralÄ±m.

#### 3) Kurulum
Minikube bir sanallaÅŸtÄ±rmaya ihtiyaÃ§ duyar, Ã§Ã¼nkÃ¼ daha Ã¶nce bahsettiÄŸimiz gibi bir VirtualBox kurulumunda veya bazÄ± hipervizÃ¶rlerde Ã§alÄ±ÅŸacaktÄ±r. Bu nedenle bir tÃ¼r hipervizÃ¶r yÃ¼klemeniz gerekecektir. VirtualBox olabilir. Hyperkit yÃ¼kleyeceÄŸim ama bu adÄ±m adÄ±m talimatlarda da yer alacak. Size Linux'a nasÄ±l kurulacaÄŸÄ±nÄ± gÃ¶stereceÄŸim.

```shell
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube && rm minikube-linux-amd64
```

Åimdi her ÅŸeyin kurulduÄŸundan emin olalÄ±m ve komutlarÄ± kontrol edelim. Yani, `minikube` komutu Ã§alÄ±ÅŸmalÄ±:

```
c3ng0@ubn:~$ minikube start

ğŸ˜„  minikube v1.33.1 on Ubuntu 22.04
âœ¨  Automatically selected the docker driver. Other choices: kvm2, qemu2, none, ssh
ğŸ“Œ  Using Docker driver with root privileges
ğŸ‘  Starting "minikube" primary control-plane node in "minikube" cluster
ğŸšœ  Pulling base image v0.0.44 ...
ğŸ’¾  Downloading Kubernetes v1.30.0 preload ...
    > preloaded-images-k8s-v18-v1...:  112.62 MiB / 342.90 MiB  32.84% 5.18 MiB
    > gcr.io/k8s-minikube/kicbase...:  70.41 MiB / 481.58 MiB  14.62% 2.65 MiB
    > index.docker.io/kicbase/sta...:  481.58 MiB / 481.58 MiB  100.00% 11.15 M
â—  minikube was unable to download gcr.io/k8s-minikube/kicbase:v0.0.44, but successfully downloaded docker.io/kicbase/stable:v0.0.44 as a fallback image
ğŸ”¥  Creating docker container (CPUs=2, Memory=2200MB) ...
    > kubectl.sha256:  64 B / 64 B [-------------------------] 100.00% ? p/s 0s
    > kubeadm.sha256:  64 B / 64 B [-------------------------] 100.00% ? p/s 0s
    > kubelet.sha256:  64 B / 64 B [-------------------------] 100.00% ? p/s 0s
    > kubectl:  49.07 MiB / 49.07 MiB [------------] 100.00% 14.58 MiB p/s 3.6s
    > kubeadm:  47.92 MiB / 47.92 MiB [--------------] 100.00% 3.97 MiB p/s 12s
    > kubelet:  95.46 MiB / 95.46 MiB [--------------] 100.00% 6.52 MiB p/s 15s

    â–ª Generating certificates and keys ...
    â–ª Booting up control plane ...
    â–ª Configuring RBAC rules ...
ğŸ”—  Configuring bridge CNI (Container Networking Interface) ...
ğŸ”  Verifying Kubernetes components...
    â–ª Using image gcr.io/k8s-minikube/storage-provisioner:v5
ğŸŒŸ  Enabled addons: storage-provisioner, default-storageclass
ğŸ’¡  kubectl not found. If you need it, try: 'minikube kubectl -- get pods -A'
ğŸ„  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

Ve `kubectl` indirmemiz gerekiyor:

```bash
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
```

Binary'i doÄŸrula(opsiyonel)

kubectl checksumfile indir:

```bash
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"   
```

Validate the kubectl binary against the checksum file:

```bash
echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check
```

   If valid, the output is:

```console
kubectl: OK
```

- Install kubectl

```bash
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
```

- Test to ensure the version you installed is up-to-date:
```bash
kubectl version --client
```

![](images/38.png)

daha fazlasÄ± iÃ§in [kubernetes.io](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/)

Ve gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Minikube oldukÃ§a basit bir komut satÄ±rÄ± aracÄ± ile birlikte gelir. Bu tek bir komutla tÃ¼m Kubernetes kÃ¼mesini bu tek dÃ¼ÄŸÃ¼m kurulumunda hÄ±zlÄ±ca baÅŸlatabilir ve onunla iÅŸler yapabilirsiniz ve durdurabilir veya silebilirsiniz. OldukÃ§a kolay.


## Ä°lk Cluster


Åimdi her ikisini de kurduÄŸumuza ve komutlarÄ±n hazÄ±r olduÄŸuna gÃ¶re, aslÄ±nda bir Minikube Kubernetes kÃ¼mesi oluÅŸturalÄ±m. Ve gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi bir baÅŸlatma komutu var:

```bash
minikube start
```

iÅŸte Minikube ile bir Kubernetes kÃ¼mesini nasÄ±l baÅŸlatacaÄŸÄ±mÄ±z:

```bash
minikube start --vm-driver=kvm
```

Burada, kurulu hipervizÃ¶rÃ¼n devreye girdiÄŸini gÃ¶rebilirsiniz Ã§Ã¼nkÃ¼ Minikube'un bir Sanal ortamda Ã§alÄ±ÅŸmasÄ± gerektiÄŸinden, Minikube'a hangi hipervizÃ¶rÃ¼ kullanmasÄ± gerektiÄŸini sÃ¶yleyeceÄŸiz. Bunun iÃ§in, `--vm-driver` olarak adlandÄ±rÄ±lan bir seÃ§enek belirleyeceÄŸiz ve burada bende kurulu olan `kvm`'i ayarladÄ±m.

Bunu yÃ¼rÃ¼ttÃ¼ÄŸÃ¼mde bir ÅŸeyler indirecek, yani ilk kez yapÄ±yorsanÄ±z biraz daha uzun sÃ¼rebilir.

![](images/39.png)

Ve bahsettiÄŸim gibi, Minikube'un Docker Ã§alÄ±ÅŸma zamanÄ± veya Docker Daemon Ã¶nceden yÃ¼klÃ¼, bu yÃ¼zden makinenizde Docker yoksa bile Ã§alÄ±ÅŸacak. Yani, Docker zaten yÃ¼klÃ¼ olduÄŸundan, iÃ§inde konteynerler oluÅŸturabilirsiniz ki bu, Docker'Ä±n zaten yÃ¼klÃ¼ olmadÄ±ÄŸÄ± bir durumda oldukÃ§a iyi bir Ã¶zelliktir.

---

TamamlandÄ±. ArtÄ±k `kubectl`, Minikube'u kullanacak ÅŸekilde yapÄ±landÄ±rÄ±lmÄ±ÅŸ durumda, bu da Minikube cluster'Ä±nÄ±n kurulduÄŸu anlamÄ±na gelir.

![](images/40.png)

Kubernetes KÃ¼mesi ile etkileÅŸimde bulunmak iÃ§in tasarlanmÄ±ÅŸ olan `kubectl` komutu da o Minikube kÃ¼mesi ile baÄŸlantÄ±lÄ±dÄ±r, bu da eÄŸer ÅŸunu yaparsam:

```bash
kubectl get nodes
```

Bu, Kubernetes kÃ¼mesinin dÃ¼ÄŸÃ¼mlerinin durumunu bana bildirir, bana bir Minikube node'unun hazÄ±r olduÄŸunu sÃ¶yleyecek ve gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi aÃ§Ä±kÃ§a master processleri Ã§alÄ±ÅŸtÄ±rmalÄ± Ã§Ã¼nkÃ¼ sadece bir node var.

![](images/41.png)

Ve ayrÄ±ca Minikube'Ä±n durumunu alabilirim:

```bash
minikube status
```

![](images/42.png)

Yani, ana makinede kubelet adlÄ± bir hizmetin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yorum, bu da aslÄ±nda konteyner Ã§alÄ±ÅŸma zamanÄ±nÄ± kullanarak pod'larÄ± Ã§alÄ±ÅŸtÄ±ran bir hizmettir, yani temelde her ÅŸey Ã§alÄ±ÅŸÄ±yor.

Buradan itibaren mini Kub kÃ¼mesi ile `kubectl` komut satÄ±rÄ± aracÄ±lÄ±ÄŸÄ±yla etkileÅŸime geÃ§eceÄŸiz. Minicube sadece cluster baÅŸlatma ve silme iÃ§in kullanÄ±lÄ±r, ancak configuring ve diÄŸer her ÅŸeyi `kubectl` aracÄ±lÄ±ÄŸÄ±yla yapacaÄŸÄ±z.

---

- **The label applied to control-plane nodes "node-role.kubernetes.io/master" is now deprecated and will be removed in a future release after a GA deprecation period.**
- **Introduce a new label "node-role.kubernetes.io/control-plane" that will be applied in parallel to "node-role.kubernetes.io/master" until the removal of the "node-role.kubernetes.io/master" label.**


## Ana Kubectl KomutlarÄ±

Bu yazÄ±mda size bazÄ± temel Kubectl komutlarÄ±nÄ± gÃ¶stereceÄŸim ve minikube'da nasÄ±l create ve debug Parts yapacaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸim.

Cubectl'i clusterda herhangi bir ÅŸey yapmak iÃ§in kullanacaksÄ±nÄ±z, components oluÅŸturmak, status almak, vb.

* Ä°lk olarak, node'larÄ±n durumunu alacaÄŸÄ±z.

```bash
kubectl get nodes
```

Bu komutu kullanarak node'larÄ±n durumunu alÄ±yoruz.

```bash
c3ng0@ubn:~$ kubectl get nodes
NAME       STATUS   ROLES           AGE    VERSION
minikube   Ready    control-plane   145m   v1.30.0
```

GÃ¶rÃ¼yoruz ki bir node var ve her ÅŸey o node'da Ã§alÄ±ÅŸÄ±yor Ã§Ã¼nkÃ¼ bu bir `minikube`.

* Pod'larÄ± kontrol edebilirim ve herhangi birimim olmadÄ±ÄŸÄ± iÃ§in sonuÃ§ yok.

```bash
kubectl get pod
```

* Services kontrol edebilirim, varsayÄ±lan bir hizmetim var.

```bash
kubectl get services
```

```bash
c3ng0@ubn:~$ kubectl get services
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   148m
```

---

Åimdi, herhangi bir Pod'umuz olmadÄ±ÄŸÄ± iÃ§in bir tane oluÅŸturacaÄŸÄ±z ve Kubernetes bileÅŸenleri oluÅŸturmanÄ±n bir Kubectl create komutu olduÄŸunu hatÄ±rlayalÄ±m. Kubectl create komutunu kullanarak tÃ¼m bu bileÅŸenleri oluÅŸturabilirim.

* Ancak listede `Pod` yok Ã§Ã¼nkÃ¼ Kubernetes dÃ¼nyasÄ±nda, Pod, Kubernetes clusterÄ±nÄ±n en kÃ¼Ã§Ã¼k birimidir ve genellikle, Pod'larÄ± doÄŸrudan oluÅŸturulmaz. Veya Pod'larla doÄŸrudan Ã§alÄ±ÅŸÄ±lmaz. Pod'larÄ±n Ã¼zerinde bir soyutlama katmanÄ±`(abstraction over Pods)` vardÄ±r, buna Â·`deployment`Â· denir. Ä°ÅŸte bu yaratmak Ã¼zere olduÄŸumuz ÅŸey ve bu, altÄ±ndaki parÃ§alarÄ± oluÅŸturacak.

```bash
Usage:
   kubectl create deployment NAME --image=image -- [COMMAND] [args...] [options]
```

* **NAME**: deployment'a isim vermeliyiz
* **--image=**: oluÅŸturacaÄŸÄ±mÄ±z container image'i

Åimdi bir nginx daÄŸÄ±tÄ±mÄ± oluÅŸturalÄ±m.

```bash
c3ng0@ubn:~$ kubectl create deployment nginx-depl --image=nginx
deployment.apps/nginx-depl created
```

 * Nginx gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼, Docker Hub'dan indirecektir. Bu komutu yÃ¼rÃ¼tÃ¼rsem, gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi nginx deployment oluÅŸturuldu.

```bash
c3ng0@ubn:~$ kubevtl get deployment
NAME         READY   UP-TO-DATE   AVAILABLE   AGE
nginx-depl   0/1     1            0           15s
```

 * OluÅŸturulmuÅŸ bir deployment olduÄŸunu gÃ¶rÃ¼yorum ve burada "hazÄ±r deÄŸil" durumunda olduÄŸunu gÃ¶rÃ¼yorum.

```bash
c3ng0@ubn:~$ kubectl get pod
NAME                          READY   STATUS    RESTARTS   AGE
nginx-depl-85c9d7c5f4-g4lwt   0/1     Creating  0          31s
```

 * ArtÄ±k bir Pod'um var. Name deÄŸeri, prefix ve rastgele bir hash'e sahiptir. Burada "konteyner oluÅŸturuluyor" yazÄ±yor, yani henÃ¼z hazÄ±r deÄŸil. Bir sÃ¼re bekleyince Ã§alÄ±ÅŸÄ±yor.

 * Bir deployment oluÅŸturduÄŸumda, deployment, Pod oluÅŸturmak iÃ§in gereken tÃ¼m bilgilere veya blueprintlere sahiptir.

![](images/43.png)

 * Bu en temel yapÄ±landÄ±rmadÄ±r, sadece adÄ± ve gÃ¶rÃ¼ntÃ¼sÃ¼ bu kadar, geri kalanÄ± default.

 * Deployment ve Pod arasÄ±nda bir baÅŸka katman vardÄ±r ve bu, otomatik olarak kubernetes tarafÄ±ndan yÃ¶netilen ==replicaset=='tir.
 * kubectl get replica set yaparsam, bir nginx replica set hash'im olduÄŸunu gÃ¶rÃ¼yorum. Ve burada, Pod adÄ±nÄ±n bir deployment prefix, replica set'in ID'si ve son olarak kendi ID'si olduÄŸunu gÃ¶rebilirsiniz. Pod adÄ± bu ÅŸekilde oluÅŸmaktadÄ±r. Replica set, Pod'un tÃ¼m replikalarÄ±nÄ± yÃ¶netir. Biz hiÃ§bir zaman replica set oluÅŸturmayacak, silmeyecek veya gÃ¼ncellemeyeceÄŸiz. DoÄŸrudan deploymentlar ile Ã§alÄ±ÅŸacaÄŸÄ±z. Bu daha uygun Ã§Ã¼nkÃ¼ deploymentlarda Pod blueprintini tamamen yapÄ±landÄ±rabilirsiniz. Pod'un kaÃ§ replikasÄ±na ihtiyacÄ±nÄ±z olduÄŸunu belirtebilir ve geri kalan configuration'u orada yapabilirsiniz.

### LayerlarÄ±n Ã§alÄ±ÅŸma ÅŸekli:

 * Ä°lk olarak Deployment, ReplicaSet'i yÃ¶netir.
 * ReplicaSet, o Pod'un tÃ¼m replikalarÄ±nÄ± yÃ¶netir.
 * Pod, bir konteynerin soyutlamasÄ±dÄ±r.
 Deployment'tan aÅŸaÄŸÄ±daki her ÅŸey otomatik olarak kubernetes tarafÄ±ndan yÃ¶netilmelidir.

Ã–rneÄŸin, kullanÄ±ldÄ±ÄŸÄ± image gibi bir ÅŸeyi doÄŸrudan bir deployment iÃ§erisinde dÃ¼zenlemem gerekecek, Pod iÃ§inde deÄŸil. Ã–yleyse hemen yapalÄ±m.

```python
c3ng0@ubn:~$ kubectl edit deployment nginx-depl
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  creationTimestamp: "2024-05-14T11:31:36Z"
  generation: 1
  labels:
    app: nginx-depl
  name: nginx-depl
  namespace: default
  resourceVersion: "9431"
  uid: 66d185d6-b628-4d10-b3bc-4aea093dfc59
spec:
  progressDeadlineSeconds: 600
  replicas: 1
...
...
...
```


Deployment oluÅŸtururken verdiÄŸimiz iki seÃ§enek dÄ±ÅŸÄ±nda her ÅŸeyin otomatik olarak oluÅŸturulmuÅŸ bir deployment, otomatik olarak oluÅŸturulmuÅŸ bir yapÄ±landÄ±rma dosyasÄ±nÄ± alÄ±yoruz.
Åimdilik sadece resmi aÃ§Ä±p istediÄŸim versiyonu 1.16'ya sabitlemek istediÄŸimi varsayalÄ±m ve bu deÄŸiÅŸikliÄŸi kaydedelim.

```
    spec:
      containers:
-       - image: nginx
---
    spec:
      containers:
+       - image: nginx:1.16

```

Ve gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi daÄŸÄ±tÄ±m dÃ¼zenlendi.

![](images/44.png)

Åimdi `kubectl get pod` yaparsam , eski pod'umu gÃ¶rÃ¼rÃ¼m.

![](images/45.png)

* Eski Pod sona erdi ve yeni pod baÅŸladÄ±.

EÄŸer ReplicaSet'i gÃ¶rÃ¼ntÃ¼lersem, eski olanÄ±n iÃ§inde pod olmadÄ±ÄŸÄ±nÄ± ve yeni bir tane oluÅŸturulduÄŸunu gÃ¶rÃ¼yorum.

![](images/46.png)

Yani sonuÃ§ olarak deployment yapÄ±landÄ±rmasÄ±nÄ± dÃ¼zenledik ve altÄ±ndaki her ÅŸey otomatik olarak gÃ¼ncellendi. Bu yaptÄ±ÄŸÄ±mÄ±z, Kubernetes'in sihrine ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na bir Ã¶rnektir.

---

### Debugging Pods

Bir diÄŸer Ã§ok pratik komut ise `kubectl logs`, bu aslÄ±nda Pod iÃ§inde Ã§alÄ±ÅŸan uygulamanÄ±n neyi kaydettiÄŸini gÃ¶sterir.

```bash
kubectl logs [POD_NAME]
```

LoglarÄ± gÃ¶rÃ¼ntÃ¼lemeden Ã¶nce Nginx hiÃ§bir ÅŸey kaydetmediÄŸi iÃ§in baÅŸka bir daÄŸÄ±tÄ±m oluÅŸturalÄ±m. Mongodb'den oluÅŸturalÄ±m ve adÄ±na `mongo-depl` verelim.

![](images/47.png)

Åimdi mongodb deployment oluÅŸturuluyor.

![](images/48.png)

Åu anda loglara bakabiliriz:

![](images/49.png)

* `kubectl describe pod [POD_NAME]` events sekmesinde bize state deÄŸiÅŸikliklerini verir.

![](images/50.png)

Loglamak, uygulamanÄ±n gerÃ§ekte neyi yazdÄ±ÄŸÄ±nÄ± gÃ¶rmede ve hata ayÄ±klamada yardÄ±mcÄ± olmaktadÄ±r.

BaÅŸka bir Ã§ok kullanÄ±ÅŸlÄ± komut, `kubectl exec`tir. Debugging yaparken, bir ÅŸey Ã§alÄ±ÅŸmÄ±yorsa veya sadece Pod'un iÃ§eriÄŸini kontrol etmek iÃ§in kullanÄ±lÄ±r.
BasitÃ§e aÃ§Ä±klayacak olursak, Ã§alÄ±ÅŸan Pod'dan shell alÄ±r. bu yÃ¼zden:
```
kubectl exec -it [POD_NAME] -- bin/bash
```
* -it = **interactive terminal**

![](images/51.png)

Bu komutla mongodb uygulama konteynerinin terminalini alÄ±yoruz ve ÅŸu anda root kullanÄ±cÄ±sÄ± olarak mongodb konteynerinin iÃ§indeyiz.
Exec, hata ayÄ±klama veya bir ÅŸeyleri test etmek veya denemek istediÄŸinizde kullanÄ±ÅŸlÄ±dÄ±r. KonteynÄ±ra girebilir veya terminali alabilir ve orada bazÄ± komutlar Ã§alÄ±ÅŸtÄ±rabilirsiniz.

---

### Delete deployment - Apply configuration file

Tabii ki Cube CTL ile potlarÄ± silebilirim,
Ã–nce deployment'larÄ± ve podlarÄ± gÃ¶rÃ¼ntÃ¼leyelim.

![](images/52.png)

```
kubectl delete deployment [deployment_name]
```

![](images/53.png)

kontrol ederseniz Pod'un sonlandÄ±ÄŸÄ±nÄ± ve eÄŸer replica set alÄ±rsanÄ±z, mongodb replicasetinin de gittiÄŸini gÃ¶rebilirsiniz.

TÃ¼m crud iÅŸlemleri (create,update,delete vb.) deployment seviyesinde gerÃ§ekleÅŸir ve altÄ±ndaki her ÅŸey otomatik olarak takip eder. AynÄ± ÅŸekilde Services gibi diÄŸer Kubernetes kaynaklarÄ± oluÅŸturabiliriz.

Ancak fark ettiÄŸiniz gibi, Kubectl ile deployment gibi kubernetes bileÅŸenlerini oluÅŸtururken, tÃ¼m bu seÃ§enekleri komut satÄ±rÄ±nda belirtmeniz gerekir.

* AdÄ± belirtmeniz gerekir.
* Image'i belirtmeniz gerekir
* option1
* option2..  vb. olabilir.

Elbette bir deployment'ta veya bir Pod'ta yapÄ±landÄ±rmak istediÄŸiniz birÃ§ok ÅŸey olabilir ve aÃ§Ä±kÃ§asÄ± bunlarÄ±n hepsini komut satÄ±rÄ±nda yazmak pratik olmayacaktÄ±r.Pratikte bunun iÃ§in genellikle Kubernetes yapÄ±landÄ±rma dosyalarÄ±yla Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z, yani oluÅŸturduÄŸunuz bileÅŸenin tÃ¼rÃ¼, bileÅŸenin adÄ±, hangi gÃ¶rÃ¼ntÃ¼ye dayandÄ±ÄŸÄ± ve diÄŸer tÃ¼m seÃ§enekler bir yapÄ±landÄ±rma dosyasÄ±nda toplanÄ±r ve sadece cubectl'e bu yapÄ±landÄ±rma dosyasÄ±nÄ± yÃ¼rÃ¼tmesini sÃ¶ylersiniz ve bunu yapmanÄ±n yolu cubectl apply komutunu kullanmaktÄ±r.

### kubectl apply

Apply, temelde dosyayÄ±, yapÄ±landÄ±rma dosyasÄ±nÄ± bir parametre olarak alÄ±r ve orada ne yazdÄ±ysanÄ±z yapar.

```bash
kubectl apply -f [file_name]
```

Apply, "-f" iÃ§in bir seÃ§enek alÄ±r ve bu dosyanÄ±n adÄ±nÄ± belirtir ve genellikle bu dosyalar iÃ§in kullanÄ±lan biÃ§im YAML'dir ve bu, dosyadaki her ÅŸeyi yÃ¼rÃ¼ten komuttur. Bu yÃ¼zden aslÄ±nda bunu yapÄ±landÄ±rma dosyasÄ± olarak adlandÄ±racaÄŸÄ±z.

Ã–rnek olarak Ã§ok basit, temel bir  `nginx-deployment.yaml` deployment dosyasÄ± oluÅŸturalÄ±m.

Deployment iÃ§in temel yapÄ±landÄ±rma:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.16
        ports:
        - containerPort: 80
```

* Åu an iÃ§in gerekli olan satÄ±rlarÄ±, aÅŸaÄŸÄ±da inceleyelim.
```yml
kind: Deployment
## Ne oluÅŸturmak istediÄŸimizi belirtiyoruz, Deployment oluÅŸturmak istiyoruz.
```

```yml
name: nginx-deployment
## OluÅŸturacaÄŸÄ±mÄ±z Deployment ismi.
```

```yml
spec:            ## specification for deployment
  replicas: 1    ## Pod'lardan oluÅŸturulacak replika sayÄ±sÄ±
```

```yml
  template:
    metadata:
      labels:
        app: nginx
    spec:    ## specification for pods
      containers:
      - name: nginx
        image: nginx:1.16   ## Konteyner image'imiz iÃ§in nginx versiyonu
        ports:
        - containerPort: 80 ## Binding Port
## Bu alan olutÅŸturacaÄŸÄ±mÄ±z deployment'a ait blueprint
```

Bu, bizim config  dosyamÄ±z ve buna bir kere sahip olduktan sonra, bu yapÄ±landÄ±rmayÄ± istediÄŸimiz zaman uygulayabiliriz.

![](images/54.png)

Deployment oluÅŸturuldu, ÅŸimdi podu gÃ¶rÃ¼ntÃ¼lersem, nginx daÄŸÄ±tÄ±mÄ± podu oluÅŸturuldu ve Ã§alÄ±ÅŸÄ±yor olduÄŸunu gÃ¶rÃ¼rÃ¼z.

![](images/55.png)

AyrÄ±ca daÄŸÄ±tÄ±mÄ±n 3 dakika 57 saniye Ã¶nce oluÅŸturulduÄŸunu gÃ¶rÃ¼yorum. EÄŸer bu deployment'ta bir ÅŸeyleri deÄŸiÅŸtirmek istersem, sadece yerel yapÄ±landÄ±rmamÄ± deÄŸiÅŸtirmem yeterlidir. Ã–rneÄŸin, bir yerine iki replika istersek bunu tekrar uygulayabilirim ve deployment nginx daÄŸÄ±tÄ±mÄ± olarak tekrar yapÄ±landÄ±rÄ±lacaktÄ±r.

![](images/56.png)

![](images/57.png)

Fark ettiyseniz Ã§Ä±ktÄ±da bize "configured" dendi. Fark ÅŸu ki, Kubernetes, nginx deployment'Ä±nÄ±n var olmadÄ±ÄŸÄ±nÄ± algÄ±larsa, yeni bir tane oluÅŸturacak, ancak eÄŸer deployment zaten varsa, yapÄ±landÄ±rma dosyasÄ±nÄ± uyguladÄ±ÄŸÄ±mÄ±zd, onu gÃ¼ncellemesi gerektiÄŸini bilecek ve yeni bir deployment oluÅŸturmak yerine eski deployment'Ä± cofigure edecek.

![](images/58.png)

Eski deployment hala ayakta (9m45s) fakat yeni bir replika oluÅŸturuldu(3m22s) Ã§Ã¼nkÃ¼ replika sayÄ±sÄ±nÄ± arttÄ±rdÄ±k. yani `kubectl apply` ile bir component oluÅŸturabilir ve gÃ¼ncelleyebilirsiniz. Elbette Services, Volumes gibi diÄŸer kubernetes bileÅŸenlerine de ayar Ã§ekebilirsiniz.

---

Ã–zetlemek gerekirse, bu yazÄ±da birkaÃ§ cubectl komutuna baktÄ±k, bir component oluÅŸturmayÄ±, nasÄ±l configure edeceÄŸimizi ve sileceÄŸimizi gÃ¶rdÃ¼k. Pod'larÄ±n, deployment'larÄ±n, replikaset'lerinin vb. state'lerini nasÄ±l alacaÄŸÄ±mÄ±zÄ± gÃ¶rdÃ¼k. AyrÄ±ca Pod'un iÃ§indeki uygulamanÄ±n konsola yazdÄ±ÄŸÄ± her ÅŸeyi nasÄ±l kaydedeceÄŸimizi gÃ¶rdÃ¼k ve `cubectl exec`'i kullanarak Ã§alÄ±ÅŸan bir konteynerdan nasÄ±l shell alacaÄŸÄ±mÄ±zÄ± gÃ¶rdÃ¼k. Son olarak, kubernetes yapÄ±landÄ±rma dosyasÄ±nÄ± ve `cubectl apply` komutunu kullanarak componentleri nasÄ±l oluÅŸturup gÃ¼ncelleyeceÄŸimizi gÃ¶rdÃ¼k.
Son olarak azÄ±cÄ±k da `kubectl describe` komutunu gÃ¶rdÃ¼k, bu da bir konteynerin bir Pod'da sorun giderme iÃ§in ek bilgi almak istediÄŸinizde kullandÄ±ÄŸÄ±nÄ±z bir komuttu.

#### Crud Commands:
* Create deployment      ->              `kubectl create deployment [name]`
* Edit deployment           ->              `kubectl edit deployment [name]`
* Delete deployment      ->               `kubectl delete deployment [name]`

#### Status of different K8s components
* `kubectl get nodes | pod | services | replicaset | deployment`

#### Debugging pods
* Log to console                     ->              `kubectl logs [pod_name]
* Get interactive Terminal      ->              `kubectl exec -it [pod_name] -- /bin/bash`
* Get info about pod              ->              `kubectl describe pod [pod_name]`  

#### Use configuration file for CRUD
* Apply a configuration file          ->        `kubectl apply -f [file_name]`
* Delete with configuration file    ->        `kubectl delete -f [file_name]`


---
